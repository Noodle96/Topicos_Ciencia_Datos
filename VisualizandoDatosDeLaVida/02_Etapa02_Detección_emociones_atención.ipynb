{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa68b95",
   "metadata": {},
   "source": [
    "### Etapa 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c42e7",
   "metadata": {},
   "source": [
    "- **Módulo 01 de Detección de emociones con DeepFace**\n",
    "- *DeepFace retorna:*\n",
    "    - La emoción dominante.\n",
    "    - Un diccionario con las probabilidades de cada emoción.\n",
    "- **Módulo 02 de detección de atención (básica) con MediaPipe**\n",
    "- *Métrica: EAR (Eye Aspect Ratio):*\n",
    "    - Detectaremos cuánto están abiertos los ojos, lo cual se relaciona con atención o fatiga. El cálculo se puede hacer con los puntos de los ojos usando MediaPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd30a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "from deepface import DeepFace\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b554557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ear(eye_points: List[Tuple[float, float]]) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Eye Aspect Ratio (EAR) para estimar apertura ocular.\n",
    "    \"\"\"\n",
    "    A: float = math.dist(eye_points[1], eye_points[5])\n",
    "    B: float = math.dist(eye_points[2], eye_points[4])\n",
    "    C: float = math.dist(eye_points[0], eye_points[3])\n",
    "    return (A + B) / (2.0 * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b34f5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ear(eye_points: List[Tuple[float, float]]) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Eye Aspect Ratio (EAR) para estimar apertura ocular.\n",
    "    \"\"\"\n",
    "    A: float = math.dist(eye_points[1], eye_points[5])\n",
    "    B: float = math.dist(eye_points[2], eye_points[4])\n",
    "    C: float = math.dist(eye_points[0], eye_points[3])\n",
    "    return (A + B) / (2.0 * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75190550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ear_from_image(image_path: str) -> float:\n",
    "    \"\"\"\n",
    "    Procesa una imagen para calcular el EAR usando MediaPipe.\n",
    "    Retorna -1.0 si no se detecta rostro.\n",
    "    \"\"\"\n",
    "    mp_face_mesh: mp.solutions.face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "    image: cv2.typing.MatLike = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return -1.0  # Imagen inválida o no leída\n",
    "\n",
    "    image_rgb: cv2.typing.MatLike = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1) as face_mesh:\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if not results.multi_face_landmarks:\n",
    "            return -1.0\n",
    "\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "        # Índices para el ojo derecho (MediaPipe)\n",
    "        right_eye_indices: List[int] = [33, 160, 158, 133, 153, 144]\n",
    "        height: int\n",
    "        width: int\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        right_eye: List[Tuple[float, float]] = [\n",
    "            (face_landmarks.landmark[i].x * width, face_landmarks.landmark[i].y * height)\n",
    "            for i in right_eye_indices\n",
    "        ]\n",
    "\n",
    "        ear: float = compute_ear(right_eye)\n",
    "        return round(ear, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c41fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_attention_from_ear(ear: float, threshold: float = 0.25) -> str:\n",
    "    \"\"\"\n",
    "    Clasifica el estado de atención según el valor EAR.\n",
    "    \"\"\"\n",
    "    if ear == -1.0:\n",
    "        return \"no_face\"\n",
    "    elif ear < threshold:\n",
    "        return \"drowsy\"\n",
    "    else:\n",
    "        return \"attentive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d4037e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotion(image_path: str) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Usa DeepFace para detectar la emoción dominante en una imagen.\n",
    "    Devuelve ('unknown', 0.0) si hay error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result: dict = DeepFace.analyze(\n",
    "            img_path=image_path,\n",
    "            actions=[\"emotion\"],\n",
    "            enforce_detection=False\n",
    "        )[0]\n",
    "\n",
    "        emotion: str = result[\"dominant_emotion\"]\n",
    "        score: float = round(result[\"emotion\"][emotion], 2)\n",
    "        return emotion, score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ DeepFace error en '{image_path}': {e}\")\n",
    "        return \"unknown\", 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c17bc8",
   "metadata": {},
   "source": [
    "***Pipeline Principal***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cba8c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1746557006.282565   68512 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557006.287705   68512 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557007.289534   68524 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557007.293384   68524 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557008.211360   68534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557008.216344   68534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557009.152681   68548 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557009.158061   68548 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557010.130054   68560 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557010.134987   68562 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557011.111174   68572 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557011.115284   68572 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557012.101600   68584 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557012.105363   68584 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557013.027570   68596 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557013.031551   68596 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557013.905870   68608 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557013.909782   68615 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557014.797213   68619 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557014.804205   68619 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557015.777566   68632 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557015.783010   68632 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557016.738514   68645 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557016.742405   68645 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557017.711946   68656 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557017.716348   68656 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557018.669127   68669 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557018.672638   68669 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557019.536927   68679 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557019.541301   68679 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557019.904200   68693 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557019.908211   68696 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557020.797455   68706 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557020.802899   68706 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557021.153846   68716 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557021.157793   68716 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557022.114705   68727 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557022.118588   68727 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557023.049453   68739 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557023.055987   68748 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'emotion_attention_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1746557023.990142   68754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746557023.993948   68754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def analyze_video_frames(\n",
    "    frames_folder: str,\n",
    "    output_csv_path: str,\n",
    "    attention_threshold: float = 0.25\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Analiza todos los frames de una carpeta para emociones y atención.\n",
    "    Guarda los resultados en un CSV.\n",
    "    \"\"\"\n",
    "    results: List[dict] = []\n",
    "\n",
    "    for filename in sorted(os.listdir(frames_folder)):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        frame_path: str = os.path.join(frames_folder, filename)\n",
    "\n",
    "        # Detectar emoción con DeepFace\n",
    "        emotion: str\n",
    "        emotion_score: float\n",
    "        emotion, emotion_score = detect_emotion(frame_path)\n",
    "\n",
    "        # Calcular EAR y clasificar atención\n",
    "        ear: float = extract_ear_from_image(frame_path)\n",
    "        attention_status: str = classify_attention_from_ear(ear, threshold=attention_threshold)\n",
    "\n",
    "        # Guardar resultado\n",
    "        results.append({\n",
    "            \"frame\": filename,\n",
    "            \"emotion\": emotion,\n",
    "            \"emotion_score\": emotion_score,\n",
    "            \"EAR\": ear,\n",
    "            \"attention_status\": attention_status\n",
    "        })\n",
    "\n",
    "    # Exportar resultados\n",
    "    df: pd.DataFrame = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv_path, index=False, header=True)\n",
    "    print(f\"✅ Resultados guardados en '{output_csv_path}'\")\n",
    "\n",
    "analyze_video_frames(\"frames_output\", \"emotion_attention_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74a6238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_score</th>\n",
       "      <th>EAR</th>\n",
       "      <th>attention_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-25_12-26-31.jpg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>60.30</td>\n",
       "      <td>0.270</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-25_12-26-36.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>75.49</td>\n",
       "      <td>0.263</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-25_12-26-41.jpg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>45.28</td>\n",
       "      <td>0.282</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-25_12-26-46.jpg</td>\n",
       "      <td>fear</td>\n",
       "      <td>48.65</td>\n",
       "      <td>0.283</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-25_12-26-51.jpg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>38.52</td>\n",
       "      <td>0.164</td>\n",
       "      <td>drowsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-04-25_12-26-56.jpg</td>\n",
       "      <td>fear</td>\n",
       "      <td>33.73</td>\n",
       "      <td>0.274</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-04-25_12-27-01.jpg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>88.38</td>\n",
       "      <td>0.287</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-04-25_12-27-06.jpg</td>\n",
       "      <td>fear</td>\n",
       "      <td>56.12</td>\n",
       "      <td>0.244</td>\n",
       "      <td>drowsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-04-25_12-27-11.jpg</td>\n",
       "      <td>fear</td>\n",
       "      <td>40.90</td>\n",
       "      <td>0.312</td>\n",
       "      <td>attentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-04-25_12-27-16.jpg</td>\n",
       "      <td>sad</td>\n",
       "      <td>90.67</td>\n",
       "      <td>0.234</td>\n",
       "      <td>drowsy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     frame  emotion  emotion_score    EAR attention_status\n",
       "0  2025-04-25_12-26-31.jpg  neutral          60.30  0.270        attentive\n",
       "1  2025-04-25_12-26-36.jpg      sad          75.49  0.263        attentive\n",
       "2  2025-04-25_12-26-41.jpg  neutral          45.28  0.282        attentive\n",
       "3  2025-04-25_12-26-46.jpg     fear          48.65  0.283        attentive\n",
       "4  2025-04-25_12-26-51.jpg  neutral          38.52  0.164           drowsy\n",
       "5  2025-04-25_12-26-56.jpg     fear          33.73  0.274        attentive\n",
       "6  2025-04-25_12-27-01.jpg  neutral          88.38  0.287        attentive\n",
       "7  2025-04-25_12-27-06.jpg     fear          56.12  0.244           drowsy\n",
       "8  2025-04-25_12-27-11.jpg     fear          40.90  0.312        attentive\n",
       "9  2025-04-25_12-27-16.jpg      sad          90.67  0.234           drowsy"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emotion_attention_results.csv', header=0)\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
